{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSD 4: Baseline Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. For this Case Study assignment you should have in your current folder the ebay_boys_girls_shirts folder, holding the four CSV files describing the train and test shirts images, and the boys and girls images folders. This is what we did in CSD 1, **if you already have the data in your current folder you don't need to run this again!**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tarfile\n",
    "\n",
    "url = \"http://www.tau.ac.il/~saharon/DScourse/ebay_boys_girls_shirts.tar.gz\"\n",
    "r = requests.get(url)\n",
    "\n",
    "with open(\"ebay_boys_girls_shirts.tar\", \"wb\") as file:\n",
    "    file.write(r.content)\n",
    "\n",
    "with tarfile.open(\"ebay_boys_girls_shirts.tar\") as tar:\n",
    "    tar.extractall('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In this Case Study assignment we will try to classify an unseen shirt image as being of boys or of girls. We will use 20% of the data (training and test) for better speed, with Logistic Regression an Classification Trees.\n",
    "\n",
    "    First we need the `x_train` and `x_test` matrices, and the `y_train` and `y_test` 0/1 vectors (0 = boys, 1 = girls).\n",
    "\n",
    "    Previously on CSD2 and CSD3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import transform, color, img_as_ubyte\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def get_file_list(df, folder, n_sample = None, seed = None):\n",
    "    if n_sample is None:\n",
    "        file_ids_list = df.file_id.values\n",
    "    else:\n",
    "        file_ids_list = df.sample(n = n_sample, random_state = seed).file_id.values\n",
    "    files_list = [folder + '/' + str(file_id) + '.jpg' for file_id in file_ids_list]\n",
    "    return files_list\n",
    "\n",
    "def read_image_and_resize(f, w = 100, h = 100):\n",
    "    img = plt.imread(f)\n",
    "    img = transform.resize(img, (w, h), mode='constant', anti_aliasing=True)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        img = img_as_ubyte(img)\n",
    "    img = color.gray2rgb(img)\n",
    "    img = img[np.newaxis, :, :, :3]\n",
    "    if img.shape != (1, 100, 100, 3):\n",
    "        raise ValueError(f + str(img.shape))\n",
    "    return img\n",
    "\n",
    "def read_images_4d_array(files_list):\n",
    "    images_list = [read_image_and_resize(file) for file in files_list]\n",
    "    images_array = np.concatenate(images_list)\n",
    "    return images_array\n",
    "\n",
    "def get_images_matrix(csv_file, folder, n = None, seed = 1976):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    files_list = get_file_list(df, folder, n, seed)\n",
    "    images = read_images_4d_array(files_list)\n",
    "    return images, files_list\n",
    "\n",
    "def get_all_pixels(x):\n",
    "    return x.reshape(-1, np.prod(x.shape[1:]))\n",
    "\n",
    "def numpy_array_size_in_bytes(a):\n",
    "    return a.size * a.itemsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the above functions to get the train and test matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'ebay_boys_girls_shirts/'\n",
    "n_train = 2000\n",
    "n_test = 500\n",
    "x_boys_train, boys_train_files = get_images_matrix(folder + 'boys_train.csv', folder + 'boys', n_train)\n",
    "x_boys_test, boys_test_files = get_images_matrix(folder + 'boys_test.csv', folder + 'boys', n_test)\n",
    "x_girls_train, girls_train_files = get_images_matrix(folder + 'girls_train.csv', folder + 'girls', n_train)\n",
    "x_girls_test, girls_test_files = get_images_matrix(folder + 'girls_test.csv', folder + 'girls', n_test)\n",
    "\n",
    "x_boys_train_all = get_all_pixels(x_boys_train)\n",
    "x_boys_test_all = get_all_pixels(x_boys_test)\n",
    "x_girls_train_all = get_all_pixels(x_girls_train)\n",
    "x_girls_test_all = get_all_pixels(x_girls_test)\n",
    "\n",
    "x_train = np.vstack([x_boys_train_all, x_girls_train_all])\n",
    "x_test = np.vstack([x_boys_test_all, x_girls_test_all])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now follow the example to create `y_train` and `y_test` 0/1 1D numpy arrays, the labelled data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_boys_train = np.array([np.uint8(0)] * x_boys_train.shape[0])\n",
    "y_boys_test = np.array([np.uint8(0)] * x_boys_test.shape[0])\n",
    "y_girls_train = np.array([np.uint8(1)] * x_girls_train.shape[0])\n",
    "y_girls_test = np.array([np.uint8(1)] * x_girls_test.shape[0])\n",
    "\n",
    "y_train = np.concatenate([y_boys_train, y_girls_train])\n",
    "y_test = np.concatenate([y_boys_test, y_girls_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Always a good idea to print the shape of your matrices and their size to see there are no surprises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train Shape: 4000 X 30000, Size (bytes): 120000000\n",
      "x_test Shape: 1000 X 30000, Size (bytes): 30000000\n",
      "y_train Shape: 4000 X 1, Size (bytes): 4000\n",
      "y_test Shape: 1000 X 1, Size (bytes): 1000\n"
     ]
    }
   ],
   "source": [
    "def shape_and_size(x, name):\n",
    "    n_rows = x.shape[0]\n",
    "    if len(x.shape) == 1:\n",
    "        n_cols = 1\n",
    "    elif len(x.shape) == 2:\n",
    "        n_cols = x.shape[1]\n",
    "    else:\n",
    "        warnings.warn('Function is meaningful for 1 or 2-D numpy arrays, taking 2nd dimension as n_cols')\n",
    "        n_cols = x.shape[1]        \n",
    "    size = numpy_array_size_in_bytes(x)\n",
    "    print('%s Shape: %d X %d, Size (bytes): %d' % (name, n_rows, n_cols, size))\n",
    "\n",
    "shape_and_size(x_train, 'x_train')\n",
    "shape_and_size(x_test, 'x_test')\n",
    "shape_and_size(y_train, 'y_train')\n",
    "shape_and_size(y_test, 'y_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Start with the most basic, single predictor: the average pixel level. Can the average of all 30K pixels classify an unseen shirt image as being of boys or of girls with good accuracy?\n",
    "\n",
    "    Get the average pixel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train_av Shape: 4000 X 1, Size (bytes): 32000\n",
      "x_train_av Shape: 1000 X 1, Size (bytes): 8000\n"
     ]
    }
   ],
   "source": [
    "x_train_av = x_train.mean(axis = 1).reshape(-1, 1) # we do the reshape step so that the shape would be (4000, 1), not (4000,)\n",
    "x_test_av = x_test.mean(axis = 1).reshape(-1, 1)\n",
    "\n",
    "shape_and_size(x_train_av, 'x_train_av')\n",
    "shape_and_size(x_test_av, 'x_train_av')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate a Logistic Regression object using the [sklearn](https://scikit-learn.org/stable/) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "mod = LogisticRegression(solver='lbfgs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Might want to make the model aware of your class names, or labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.classes_ = ['boys', 'girls']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model to training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod.fit(x_train_av, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the actual Logistic Regression coefficients (we expect an intercept and a coefficient for the average pixel, the single predictor):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept: [-0.1856065]\n",
      "coefficient: [ 0.00121881]\n"
     ]
    }
   ],
   "source": [
    "print('intercept:', mod.intercept_)\n",
    "print('coefficient:', mod.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have all you need to get the Logistic Regression different formulas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log-odds[label(image)=boys] = -0.186 + (0.001) X average_pixel\n",
      "Odds[label(image)=boys] = exp[-0.186 + (0.001) X average_pixel]\n",
      "Prob[label(image)=boys] = 1 / [1 + exp[-0.186 + (0.001) X average_pixel]]\n"
     ]
    }
   ],
   "source": [
    "print('Log-odds[label(image)=boys] = %.3f + (%.3f) X average_pixel' % (mod.intercept_, mod.coef_[0]))\n",
    "print('Odds[label(image)=boys] = exp[%.3f + (%.3f) X average_pixel]' % (mod.intercept_, mod.coef_[0]))\n",
    "print('Prob[label(image)=boys] = 1 / [1 + exp[%.3f + (%.3f) X average_pixel]]' % (mod.intercept_, mod.coef_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the predicted score on test set, which may be interpreted here as P(label(image) = boys):\n",
    "\n",
    "(Make sure you can get these manually with the above formula!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAGc9JREFUeJzt3XuUXnV97/H3h3ARFAUk0BSIARsvaDXqSD31UrwjHEVaFahVvEZPdR1tPeeIl6W0LtehrYq11gsuUeAogiJIC1UiKmgrQkAuQVQuRomkEEEFhYIJ3/PH3iMP407mmcw8l0ner7X2mr1/+/b9Pck839m/vffvl6pCkqSpthl1AJKk8WSCkCR1MkFIkjqZICRJnUwQkqROJghJUicThCSpkwlCktTJBCFJ6rTtqAOYjd13372WLFky6jAkaV655JJLflZVC6fbbl4niCVLlrBy5cpRhyFJ80qSH/eznU1MkqROJghJUicThCSpkwlCktRpYAkiyT5Jvp7k6iRXJXlTW75bkhVJrml/7tqWJ8mHklyb5Iokjx9UbJKk6Q3yCmI98JaqeiTwJOANSfYHjgbOq6qlwHntMsDzgKXttBz46ABjkyRNY2AJoqrWVtWl7fztwNXAXsChwIntZicCL2znDwVOqsaFwC5JFg0qPknSpg3lHkSSJcDjgO8Ae1bVWmiSCLBHu9lewA09u61pyyRJIzDwBJHkAcDpwJur6rZNbdpR9jsDZidZnmRlkpXr1q2bqzAlSVMM9E3qJNvRJIfPVNUX2+KbkiyqqrVtE9LNbfkaYJ+e3fcGbpx6zKo6HjgeYGJi4ncSiDQulhx99kjOu/rYQ0ZyXm15BvkUU4BPAldX1Qd6Vp0FHNXOHwV8qaf85e3TTE8CfjnZFCVJGr5BXkE8GXgZcGWSy9qytwPHAqcleTXwE+DF7bpzgIOBa4E7gFcOMDZJ0jQGliCq6lt031cAeGbH9gW8YVDxSJJmxjepJUmdTBCSpE4mCElSJxOEJKmTCUKS1MkEIUnqZIKQJHUyQUiSOpkgJEmdTBCSpE4mCElSJxOEJKmTCUKS1MkEIUnqZIKQJHUyQUiSOpkgJEmdBjkm9QlJbk6yqqfs1CSXtdPqyaFIkyxJcmfPuo8NKi5JUn8GOSb1p4EPAydNFlTV4ZPzSd4P/LJn++uqatkA45EkzcAgx6S+IMmSrnVJArwEeMagzi9Jmp1R3YN4KnBTVV3TU7Zvku8mOT/JU0cUlySpNcgmpk05EjilZ3ktsLiqbknyBODMJI+qqtum7phkObAcYPHixUMJVpK2RkO/gkiyLfCnwKmTZVV1V1Xd0s5fAlwHPKxr/6o6vqomqmpi4cKFwwhZkrZKo2hiehbw/apaM1mQZGGSBe38fsBS4PoRxCZJag3yMddTgG8DD0+yJsmr21VHcN/mJYCnAVckuRz4AvD6qrp1ULFJkqY3yKeYjtxI+Ss6yk4HTh9ULJKkmfNNaklSp1E9xSRpQJYcffbIzr362ENGdm7NPa8gJEmdTBCSpE4mCElSJxOEJKmTCUKS1MkEIUnqZIKQJHUyQUiSOpkgJEmdTBCSpE4mCElSJxOEJKmTCUKS1MkEIUnqZIKQJHUa5JCjJyS5OcmqnrJjkvw0yWXtdHDPurcluTbJD5I8d1BxSZL6M8griE8DB3WUH1dVy9rpHIAk+9OMVf2odp+PJFkwwNgkSdMYWIKoqguAW/vc/FDgc1V1V1X9CLgWOGBQsUmSpjeKexBvTHJF2wS1a1u2F3BDzzZr2jJJ0ogMO0F8FHgosAxYC7y/LU/HttV1gCTLk6xMsnLdunWDiVKSNNwEUVU3VdWGqroH+AT3NiOtAfbp2XRv4MaNHOP4qpqoqomFCxcONmBJ2ooNNUEkWdSzeBgw+YTTWcARSXZIsi+wFLhomLFJku5r20EdOMkpwIHA7knWAO8GDkyyjKb5aDXwOoCquirJacD3gPXAG6pqw6BikyRNb2AJoqqO7Cj+5Ca2fy/w3kHFI0maGd+kliR1MkFIkjoNrIlJ6rXk6LNHct7Vxx4ykvNKWwKvICRJnUwQkqROJghJUicThCSpkwlCktTJBCFJ6mSCkCR1MkFIkjqZICRJnUwQkqROdrWhLdqouviQtgReQUiSOpkgJEmdTBCSpE4DSxBJTkhyc5JVPWX/kOT7Sa5IckaSXdryJUnuTHJZO31sUHFJkvrTV4JI8ujNOPangYOmlK0AHl1VjwF+CLytZ911VbWsnV6/GeeTJM2hfq8gPpbkoiR/OflX/3Sq6gLg1ill51bV+nbxQmDv/kOVJA1TXwmiqp4CvBTYB1iZ5LNJnj3Lc78K+Lee5X2TfDfJ+UmeOstjS5Jmqe/3IKrqmiTvBFYCHwIelyTA26vqizM5aZJ3AOuBz7RFa4HFVXVLkicAZyZ5VFXd1rHvcmA5wOLFi2dyWknSDPR7D+IxSY4DrgaeATy/qh7Zzh83kxMmOQr478BLq6oAququqrqlnb8EuA54WNf+VXV8VU1U1cTChQtncmpJ0gz0ewXxYeATNFcLd04WVtWN7VVFX5IcBLwV+JOquqOnfCFwa1VtSLIfsBS4vt/jSpLmXr8J4mDgzqraAJBkG+B+VXVHVZ3ctUOSU4ADgd2TrAHeTfPU0g7AiqZ1igvbJ5aeBvxtkvXABuD1VXVr13ElScPRb4L4KvAs4Fft8k7AucAfb2yHqjqyo/iTG9n2dOD0PmORJA1Bv4+53q+qJpMD7fxOgwlJkjQO+k0Qv07y+MmF9kmjOzexvSRpnuu3ienNwOeT3NguLwIOH0xIkqRx0FeCqKqLkzwCeDgQ4PtV9ZuBRiZJGqmZDBj0RGBJu8/jklBVJw0kKknSyPWVIJKcDDwUuIzmMVSAAkwQkrSF6vcKYgLYf/LNZ0nSlq/fp5hWAb83yEAkSeOl3yuI3YHvJbkIuGuysKpeMJCoJEkj12+COGaQQUiSxk+/j7men+QhwNKq+mqSnYAFgw1NkjRK/Xb3/VrgC8DH26K9gDMHFZQkafT6vUn9BuDJwG3QDB4E7DGooCRJo9dvgrirqu6eXEiyLc17EJKkLVS/CeL8JG8HdmzHov488C+DC0uSNGr9JoijgXXAlcDrgHOAvkeSkyTNP/0+xXQPzZCjnxhsOJKkcdHvU0w/SnL91KmP/U5IcnOSVT1luyVZkeSa9ueubXmSfCjJtUmu6B1/QpI0fP02MU3Q9Ob6ROCpwIeA/9fHfp8GDppSdjRwXlUtBc5rlwGeByxtp+XAR/uMTZI0AH0liKq6pWf6aVV9EHhGH/tdANw6pfhQ4MR2/kTghT3lJ1XjQmCXJIv6qoUkac712913b3PPNjRXFDtv5jn3rKq1AFW1Nsnk+xR7ATf0bLemLVu7meeRJM1Cv30xvb9nfj2wGnjJHMeSjrLfedciyXKaJigWL148xyFIkib1+xTT0+fwnDclWdRePSwCbm7L1wD79Gy3N3Dj1J2r6njgeICJiQlf1pOkAem3iemvN7W+qj4wg3OeBRwFHNv+/FJP+RuTfA74I+CXk01RkqThm8mIck+k+RIHeD5wAfe9Z/A7kpwCHAjsnmQN8G6axHBaklcDPwFe3G5+DnAwcC1wB/DKvmshSZpzMxkw6PFVdTtAkmOAz1fVaza1U1UduZFVz+zYtmg6BZQkjYF+34NYDNzds3w3sGTOo5EkjY1+ryBOBi5KcgbNk0WHAScNLCpJ0sj1+xTTe5P8G81b1ACvrKrvDi4sSdKo9dvEBLATcFtV/SOwJsm+A4pJkjQG+n3M9d00TzI9HPgUsB1NX0xPHlxoW64lR589kvOuPvaQkZxX0vzU7xXEYcALgF8DVNWNbH5XG5KkeaDfBHF3+xhqASS5/+BCkiSNg34TxGlJPk7Tw+prga/i4EGStEXr9ymm97VjUd9Gcx/iXVW1YqCRSZJGatoEkWQB8JWqehZgUpCkrcS0TUxVtQG4I8mDhhCPJGlM9Psm9X8BVyZZQfskE0BV/c+BRCVJGrl+E8TZ7SRJG+U7PluWTSaIJIur6idVdeKmtpMkbXmmuwdx5uRMktMHHIskaYxMlyB6x4neb5CBSJLGy3QJojYyL0nawk13k/qxSW6juZLYsZ2nXa6qeuBMT5jk4cCpPUX7Ae8CdgFeC6xry99eVefM9PiSpLmxyQRRVQvm+oRV9QNgGfz2JbyfAmfQjEF9XFW9b67PKUmauZmMBzEIzwSuq6ofjzgOSdIUo04QRwCn9Cy/MckVSU5IsuuogpIk9f+i3JxLsj3NGBNva4s+CryH5mb4e4D3A6/q2G85sBxg8eLFQ4l1SzGql5gkzU+jvIJ4HnBpVd0EUFU3VdWGqrqHpivxA7p2qqrjq2qiqiYWLlw4xHAlaesyygRxJD3NS0kW9aw7DFg19IgkSb81kiamJDsBzwZe11P890mW0TQxrZ6yTpI0ZCNJEFV1B/DgKWUvG0UskqRuo36KSZI0pkwQkqROJghJUicThCSpkwlCktTJBCFJ6mSCkCR1MkFIkjqZICRJnUwQkqROJghJUicThCSpkwlCktTJBCFJ6mSCkCR1MkFIkjqNZMCgcbHk6LNHHYIkja2RJYgkq4HbgQ3A+qqaSLIbcCqwhGbY0ZdU1c9HFaMkbc1G3cT09KpaVlUT7fLRwHlVtRQ4r12WJI3AqBPEVIcCJ7bzJwIvHGEskrRVG2WCKODcJJckWd6W7VlVawHan3uMLDpJ2sqN8ib1k6vqxiR7ACuSfL+fndpkshxg8eLFg4xPkrZqI7uCqKob2583A2cABwA3JVkE0P68uWO/46tqoqomFi5cOMyQJWmrMpIEkeT+SXaenAeeA6wCzgKOajc7CvjSKOKTJI2uiWlP4IwkkzF8tqq+nORi4LQkrwZ+Arx4RPFJ0lZvJAmiqq4HHttRfgvwzOFHJEmaatwec5UkjQkThCSpkwlCktTJBCFJ6mSCkCR1MkFIkjqZICRJnUwQkqROW/WIcpK2DKMaHXL1sYeM5LzD4hWEJKmTCUKS1MkEIUnqZIKQJHUyQUiSOpkgJEmdTBCSpE4mCElSp6EniCT7JPl6kquTXJXkTW35MUl+muSydjp42LFJku41ijep1wNvqapLk+wMXJJkRbvuuKp63whikiRNMfQEUVVrgbXt/O1Jrgb2GnYckqRNG+k9iCRLgMcB32mL3pjkiiQnJNl1ZIFJkkaXIJI8ADgdeHNV3QZ8FHgosIzmCuP9G9lveZKVSVauW7duaPFK0tZmJAkiyXY0yeEzVfVFgKq6qao2VNU9wCeAA7r2rarjq2qiqiYWLlw4vKAlaSsziqeYAnwSuLqqPtBTvqhns8OAVcOOTZJ0r1E8xfRk4GXAlUkua8veDhyZZBlQwGrgdSOITZLUGsVTTN8C0rHqnGHHIknaON+kliR1MkFIkjqZICRJnUwQkqROo3iKSZK2CEuOPntk51597CEDP4dXEJKkTiYISVInE4QkqZMJQpLUyQQhSepkgpAkdTJBSJI6mSAkSZ1MEJKkTiYISVInE4QkqZMJQpLUaewSRJKDkvwgybVJjh51PJK0tRqrBJFkAfDPwPOA/WnGqd5/tFFJ0tZprBIEcABwbVVdX1V3A58DDh1xTJK0VRq3BLEXcEPP8pq2TJI0ZOM2YFA6yuo+GyTLgeXt4q+S/KCP4+4O/GyWsY0D6zFerMd42arqkb+b1Tke0s9G45Yg1gD79CzvDdzYu0FVHQ8cP5ODJllZVROzD2+0rMd4sR7jxXrMvXFrYroYWJpk3yTbA0cAZ404JknaKo3VFURVrU/yRuArwALghKq6asRhSdJWaawSBEBVnQOcM8eHnVGT1BizHuPFeowX6zHHUlXTbyVJ2uqM2z0ISdKYmNcJot9uOZK8KEklmWiXX5rksp7pniTLhhd5Z4ybW5ftkpyY5MokVyd52/Ci7oxvc+uxfZJPtfW4PMmBQwu6O75N1iPJK5Ks6/k/9JqedUcluaadjhpu5L8T52zq8eUkv0jyr8ON+ndtbj2SLEvy7SRXJbkiyeHDj/4+cW5uPR6S5JK27Kokrx9KwFU1Lyeam9jXAfsB2wOXA/t3bLczcAFwITDRsf4Pgevna12APwc+187vBKwGlszDerwB+FQ7vwdwCbDNuNYDeAXw4Y59dwOub3/u2s7vOt/q0a57JvB84F9HEf8c/Xs8DFjazv8+sBbYZR7WY3tgh3b+Ae3v+e8POub5fAXRb7cc7wH+HvivjRznSOCUwYTYt9nUpYD7J9kW2BG4G7htwPFuzGzqsT9wHkBV3Qz8AhjVs+Cz6fLlucCKqrq1qn4OrAAOGlCc05lV1zVVdR5w+6CCm4HNrkdV/bCqrmnnbwRuBhYOLNJNm0097q6qu9rFHRhS6898ThDTdsuR5HHAPlW1qUvkwxl9gphNXb4A/JrmL6OfAO+rqlsHGOumzKYelwOHJtk2yb7AE7jvS5PD1G+XL3/WNlt8IclkrOPUXcxs6jFO5qQeSQ6g+Uv8usGEOa1Z1SPJPkmuaI/xd23CG6j5nCA22S1Hkm2A44C3bPQAyR8Bd1TVqrkPb0ZmU5cDgA00l8/7Am9Jst8gguzDbOpxAs0vzErgg8B/AOsHEGM/pu3yBfgXmqa8xwBfBU6cwb7DMpt6jJNZ1yPJIuBk4JVVdc9AopzerOpRVTe05X8AHJVkz4FF2prPCWK6bjl2Bh4NfCPJauBJwFmTN0VbRzD6qweYXV3+HPhyVf2mbZr5d0bXNLPZ9aiq9VX1V1W1rKoOBXYBrhlS3FP10+XLLT2X/J+gueLpa98hmk09xsms6pHkgcDZwDur6sIBx7opc/Lv0V45XAU8dUBx3udk83Kiecnvepq/midv+DxqE9t/g56b1DTJcQ2w33yuC/BW4FM0f53cH/ge8Jh5WI+dgPu3888GLhjnfw9gUc/8YcCF7fxuwI9oblDv2s7vNt/q0VN2IKO/ST2bf4/tae5tvXmUdZiDeuwN7NjO7wr8EPjDgcc86g9tlh/4we0HdR3wjrbsb4EXdGw7NUEcOPWXYT7WheaJhs/T/EXxPeB/z9N6LAF+AFxNc2n9kHGuB/B/28/8cuDrwCN69n0VcG07vXIe1+ObwDrgTpo/pp473+oB/AXwG+CynmnZPKzHs4Er2vIrgOXDiNc3qSVJnebzPQhJ0gCZICRJnUwQkqROJghJUicThCSpkwlCI5FkQ9sz5aokn0+yU1u+Y5LzkyxIsiTJJt9yT3LgTHsbTfKNnl5kk+Rr7ctUJPmPza3TbCX5apJd5+A4xyT5X3MRU8ext09yQdv3l7ZwJgiNyp3VvDX9aJoOBie7L34V8MWq2jCkOA4GLq+q2wCq6o+HdN4uJwN/OcLzT6uaTubOo+nDTFs4E4TGwTdp+pcBeCnwpakbtFcT30xyaTv1fpE/MMkZSb6X5GNtn08keU47FsCl7VXKAzrOfZ/zJflV+/PA9krmtCQ/THJsmnFELkozZsVD2+2en+Q7Sb7bXgHs2ZYvTLKiPffHk/w4ye7tur9oj3NZu25Be/qzaHoXnguPba+Mrkny2va8SfIP7VXblWnHRkhycpLf9iqa5DNJXpDkUT1xXpFkabvJme3npi3dqN4odNq6J+BX7c9tab6g/wdN9wP/2bPNEmBVO78TcL92fimwsp0/kKbb8P1o+ttfAbwI2J1mzInJ7jveCryrnf8G977B/WNg5464DqTpcnwRTffKPwX+pl33JuCD7fyu3Dt072uA97fzHwbe1s4fRNMp2+7AI2k6ZNuuXfcR4OU9578GeHDH53Uq930beHJ6ece2x9C8cbtje84baDpz/LP281kA7EnT++8i4E+AM9t9H0TTPci2wD8BL23Lt+ferh4WAOtG/X/IafCT7YgalR2TXNbOfxP4JM2X2S82sv12wIfTjPy3gWYgmEkXVdX1AElOAZ5CkzT2B/49CTRfcN/uOO5uVbWxMQ8urqq17XGvA85ty68Ent7O7w2c2vYWuj3NlyttDIcBVNWXk/y8LX8mTQdsF7dx7UgzRsGkm2m+zG/pDaSqZtqk86WquhO4M8nXaXr9fQpwSjXNdzclOR94YlWdleSfk+wB/ClwelWtT/Jt4B1J9qZp9pscV2FDkruT7LyJz05bABOERuXOqrrPMK9J7gTut5Ht/wq4CXgsTdPo1EGTmLIcmoF7pmuyWZ9km+ruAvqunvl7epbv4d7fnX8CPtB+yR5I89c7dHftPFl+YlVtbGjY+9H0fXTfnZJTgYd3bP+Bqjqpo3xjn8nGnEzTbHQEzX0gquqzSb4DHAJ8Jclrqupr7fY7sPFBuLSF8B6ExkY1I7AtSNKVJB4ErG2/yF9G08wx6YAk+7b3Hg4HvkUznOmTk/wBQJKdkjxs6kFpOgiczfgZD6JpfgI4qqf8W8BL2nM/h6YpCpobvC9q/1onyW5JHtLOB/g9muEk76OqDq/mpv7UqSs5QDP40v2SPJimueximia3w9snxBYCTwMuarf/NPDm9lxXtfHsRzMc74do7o88pi1/ME0T02/6/Iw0T5kgNG7OpWkKmeojNIOkXEjTvPTrnnXfBo4FVtE08ZxRVetoxvc9Jc0oXBcCj+g47tk0X6Cb6xjg80m+Cfysp/xvgOckuRR4Hs2If7dX1feAdwLntnGtoLkPAE3T04VVNRcDJV1EU7cLgfdUM4bAGdzbI+jXgP9TVf8JUFU30fSk+6meYxwOrGqbAh8BTCajpwPnzEGMGnP25qqxkmZI0r+uqpcN6XyLgJOq6tlzfNwdgA1tW/5/Az46tUmtY59/BM6qZizooUrzHsqVwOOr6pfTbPtFmhvwPxhKcBoZ70ForFTVd5N8PcmCGsK7EFW1Nsknkjyw2nch5shi4LS22etu4LV97LNqRMnhWTRDvn6gj+SwPc0TTyaHrYBXEJKkTt6DkCR1MkFIkjqZICRJnUwQkqROJghJUicThCSp0/8Hr0QvxzMclyQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_prob = mod.predict_proba(x_test_av)\n",
    "\n",
    "plt.hist(y_pred_prob[:, 0])\n",
    "plt.xlabel('P(label(image) = boys)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can already see the scores are not \"differentiated\", as if they're completely random, and very close to 0.5 suggesting the model is \"uncertain\".\n",
    "\n",
    "Since we used a balanced training set, it makes sence to have p = 0.5 as a cutoff threshold below which we predict \"girls\", above which we predict \"boys\".\n",
    "\n",
    "Get the predicted label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mod.predict(x_test_av) # p=0.5 is the default cutoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the confusion matrix of predicted vs. true test labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[285 215]\n",
      " [269 231]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf = confusion_matrix(y_test, y_pred)\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is slightly not readable, so we'll get pandas to help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>boys</th>\n",
       "      <th>girl</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>boys</th>\n",
       "      <td>285</td>\n",
       "      <td>215</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girl</th>\n",
       "      <td>269</td>\n",
       "      <td>231</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>554</td>\n",
       "      <td>446</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  boys  girl   All\n",
       "True                       \n",
       "boys        285   215   500\n",
       "girl        269   231   500\n",
       "All         554   446  1000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_s = np.array(['boys'] * len(y_test))\n",
    "y_pred_s = np.array(['boys'] * len(y_test))\n",
    "y_test_s[y_test == 1] = 'girls'\n",
    "y_pred_s[y_pred == 1] = 'girls'\n",
    "\n",
    "def conf_matrix(y_true, y_pred):\n",
    "    return pd.crosstab(y_true, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)\n",
    "\n",
    "conf_matrix(y_test_s, y_pred_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. You can see the average pixel preformed pretty bad in predicting the shirts images class. How do you measure it?\n",
    "\n",
    "    You can use sklearn's automatic reports to get measures such as accuracy, recall and precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        boys       0.51      0.57      0.54       500\n",
      "        girl       0.52      0.46      0.49       500\n",
      "\n",
      "   micro avg       0.52      0.52      0.52      1000\n",
      "   macro avg       0.52      0.52      0.51      1000\n",
      "weighted avg       0.52      0.52      0.51      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test_s, y_pred_s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also manually calculate these metrics yourself from the `conf` matrix (make sure you know how!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.52\n",
      "recall_boys: 0.57\n",
      "recall_girls: 0.46\n",
      "precision_boys: 0.51\n",
      "precision_girls: 0.52\n"
     ]
    }
   ],
   "source": [
    "# accuracy = P(predict correct)\n",
    "accuracy = (conf[0, 0] + conf[1, 1]) / len(y_test)\n",
    "\n",
    "# recall(boys) = P(predict boys | label boys)\n",
    "recall_boys = (conf[0, 0] / (conf[0, 0] + conf[0, 1]))\n",
    "\n",
    "# recall(girls) = P(predict girls | label girls)\n",
    "recall_girls = (conf[1, 1] / (conf[1, 0] + conf[1, 1]))\n",
    "\n",
    "# precision(boys) = P(label boys | predict boys)\n",
    "precision_boys = (conf[0, 0] / (conf[0, 0] + conf[1, 0]))\n",
    "\n",
    "# precision(boys) = P(label girls | predict girls)\n",
    "precision_girls = (conf[1, 1] / (conf[0, 1] + conf[1, 1]))\n",
    "\n",
    "print('accuracy: %.2f' % accuracy)\n",
    "print('recall_boys: %.2f' % recall_boys)\n",
    "print('recall_girls: %.2f' % recall_girls)\n",
    "print('precision_boys: %.2f' % precision_boys)\n",
    "print('precision_girls: %.2f' % precision_girls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For quickly getting the overall accuracy, this would be the default option of the `score` method of any classification model fit object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on average pixel: 0.52\n"
     ]
    }
   ],
   "source": [
    "acc = mod.score(x_test_av, y_test)\n",
    "print('Test accuracy on average pixel: %.2f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's not impressive and close to random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Let's try a model with 3 predictors: the average Red pixel, the average Green pixel and the average Blue pixel.\n",
    "\n",
    "    First, get those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train Shape: 4000 X 3, Size (bytes): 96000\n",
      "x_test Shape: 1000 X 3, Size (bytes): 24000\n"
     ]
    }
   ],
   "source": [
    "def get_average_channel(x, channel):\n",
    "    return x[:,:,:,channel].mean(axis = (1, 2)).reshape(-1, 1)\n",
    "\n",
    "def get_channels(x):\n",
    "    return np.hstack([get_average_channel(x, i) for i in range(3)])\n",
    "\n",
    "x_boys_train_av_channels = get_channels(x_boys_train)\n",
    "x_boys_test_av_channels = get_channels(x_boys_test)\n",
    "x_girls_train_av_channels = get_channels(x_girls_train)\n",
    "x_girls_test_av_channels = get_channels(x_girls_test)\n",
    "\n",
    "x_train_av_channels = np.vstack([x_boys_train_av_channels, x_girls_train_av_channels])\n",
    "x_test_av_channels = np.vstack([x_boys_test_av_channels, x_girls_test_av_channels])\n",
    "\n",
    "shape_and_size(x_train_av_channels, 'x_train')\n",
    "shape_and_size(x_test_av_channels, 'x_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model, fit it, get log-odds formula and overall test accuracy, now in a single chunk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log-odds: -0.364 + 0.008 * red + -0.011 * green + 0.004 * blue\n",
      "Test accuracy on 3 channels with LR: 0.560\n"
     ]
    }
   ],
   "source": [
    "mod = LogisticRegression(solver='lbfgs')\n",
    "mod.fit(x_train_av_channels, y_train)\n",
    "\n",
    "coef_names = ['red', 'green', 'blue']\n",
    "coef = mod.coef_[0]\n",
    "print('log-odds: %.3f + %.3f * %s + %.3f * %s + %.3f * %s' %\n",
    "      (mod.intercept_, coef[0], coef_names[0], coef[1], coef_names[1], coef[2], coef_names[2]))\n",
    "\n",
    "acc = mod.score(x_test_av_channels, y_test)\n",
    "print('Test accuracy on 3 channels with LR: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test accuracy is slightly better than when using a global average pixel but we cannot say for sure if that's not by random."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Will a classification tree perform any better with the average pixels? Probably not, but try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on 3 channels with CART: 0.558\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "mod = DecisionTreeClassifier()\n",
    "mod.fit(x_train_av_channels, y_train)\n",
    "\n",
    "acc = mod.score(x_test_av_channels, y_test)\n",
    "print('Test accuracy on 3 channels with CART: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully you can already see sklearn's consistent interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. How about Logistic Regression with all 30K pixels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on all pixels with LR: 0.699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:757: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "mod = LogisticRegression(solver='lbfgs', max_iter = 100) # have a look at LogisticRegression default parameters in the docs\n",
    "mod.fit(x_train, y_train)\n",
    "\n",
    "acc = mod.score(x_test, y_test)\n",
    "print('Test accuracy on all pixels with LR: %.3f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much more impressive, let's look at the confusion matrix now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>boys</th>\n",
       "      <th>girl</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>boys</th>\n",
       "      <td>349</td>\n",
       "      <td>151</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girl</th>\n",
       "      <td>150</td>\n",
       "      <td>350</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>499</td>\n",
       "      <td>501</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  boys  girl   All\n",
       "True                       \n",
       "boys        349   151   500\n",
       "girl        150   350   500\n",
       "All         499   501  1000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = mod.predict(x_test)\n",
    "\n",
    "y_pred_s = np.array(['boys'] * len(y_test))\n",
    "y_pred_s[y_pred == 1] = 'girls'\n",
    "\n",
    "conf_matrix(y_test_s, y_pred_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also make sure that the predicted probability score histogram looks better, more \"differentiated\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_prob = mod.predict_proba(x_test)\n",
    "\n",
    "plt.hist(y_pred_prob[:, 0])\n",
    "plt.xlabel('P(label(image) = boys)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. It is interesting to see the accuracy for images with very low and very high predicted probability score. If we took the \"girls, boys, don't know\" strategy, how better off would we be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on all pixels with LR, only 0.30 of images with very low/high scores: 0.800\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob_1d = y_pred_prob[:, 0]\n",
    "y_pred_low_high_id = np.argwhere(( y_pred_prob_1d <= 0.001) | (y_pred_prob_1d >= 0.999)).reshape(-1)\n",
    "y_pred_low_high = y_pred_prob[y_pred_low_high_id, 0]\n",
    "y_pred_low_high_temp = y_pred_low_high.copy()\n",
    "y_pred_low_high[y_pred_low_high_temp < 0.5] = 1\n",
    "y_pred_low_high[y_pred_low_high_temp > 0.5] = 0\n",
    "y_test_low_high = y_test[y_pred_low_high_id]\n",
    "\n",
    "conf = confusion_matrix(y_test_low_high, y_pred_low_high)\n",
    "acc = (conf[0, 0] + conf[1, 1]) / len(y_test_low_high)\n",
    "print('Test accuracy on all pixels with LR, only %.2f of images with very low/high scores: %.3f' % (len(y_test_low_high)/len(y_test), acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Repeat (7) and (8) with a Classification Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on all pixels with CART: 0.668\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>boys</th>\n",
       "      <th>girl</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>boys</th>\n",
       "      <td>328</td>\n",
       "      <td>172</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>girl</th>\n",
       "      <td>160</td>\n",
       "      <td>340</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>488</td>\n",
       "      <td>512</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  boys  girl   All\n",
       "True                       \n",
       "boys        328   172   500\n",
       "girl        160   340   500\n",
       "All         488   512  1000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = DecisionTreeClassifier()\n",
    "mod.fit(x_train, y_train)\n",
    "\n",
    "acc = mod.score(x_test, y_test)\n",
    "print('Test accuracy on all pixels with CART: %.3f' % acc)\n",
    "\n",
    "y_pred = mod.predict(x_test)\n",
    "\n",
    "y_pred_s = np.array(['boys'] * len(y_test))\n",
    "y_pred_s[y_pred == 1] = 'girls'\n",
    "\n",
    "conf_matrix(y_test_s, y_pred_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAFvlJREFUeJzt3X+0XWV95/H3h/BbkV8JlAHSaI2/xqVIo4uOzlRFXYojaMcfuFSog2bG2hmtnaloXRWnnbV0OoqlWhUHR2CqAiqSKq0iP5R2+BUEAUGHiAgpFFARVFAEv/PHfmKv4UnuDrnnnpvk/VrrrLP3c55z9nffJPeT/eyzn52qQpKk9W037QIkSQuTASFJ6jIgJEldBoQkqcuAkCR1GRCSpC4DQpLUZUBIkroMCElS1/bTLmBzLF68uJYtWzbtMiRpi3L55Zd/r6qWzNZviw6IZcuWsXr16mmXIUlblCTfHdPPISZJUpcBIUnqMiAkSV0GhCSpy4CQJHUZEJKkLgNCktRlQEiSugwISVLXFn0l9eZYduwXprbtG9/9wqltW5LGmugRRJIbk1yd5Mokq1vbXknOSXJ9e96ztSfJCUnWJLkqycGTrE2StHHzMcT0rKo6qKpWtPVjgXOrajlwblsHeAGwvD1WAh+ah9okSRswjXMQRwAnt+WTgRfPaD+lBhcDeyTZbwr1SZKYfEAU8KUklydZ2dr2rapbAdrzPq19f+DmGe9d29okSVMw6ZPUT6+qW5LsA5yT5Jsb6ZtOWz2o0xA0KwGWLl06N1VKkh5kokcQVXVLe74dOBN4GnDbuqGj9nx7674WOHDG2w8Abul85olVtaKqVixZMuv9LiRJD9HEAiLJw5Lstm4ZeB5wDbAKOLp1Oxo4qy2vAo5q32Y6BLhr3VCUJGn+TXKIaV/gzCTrtvOJqvq7JJcBpyc5BrgJeFnrfzZwGLAGuAd47QRrkyTNYmIBUVU3AE/utH8fOLTTXsAbJ1WPJGnTONWGJKnLgJAkdRkQkqSubXayPknaXFv7pJ8eQUiSugwISVKXASFJ6jIgJEldBoQkqcuAkCR1GRCSpC4DQpLUZUBIkroMCElSlwEhSeoyICRJXQaEJKnLgJAkdRkQkqQuA0KS1GVASJK6DAhJUpcBIUnqMiAkSV0GhCSpy4CQJHUZEJKkLgNCktRlQEiSugwISVKXASFJ6pp4QCRZlOSKJJ9v649MckmS65OclmTH1r5TW1/TXl826dokSRs2H0cQbwKum7H+HuD4qloO3Akc09qPAe6sqkcDx7d+kqQpmWhAJDkAeCHwv9p6gGcDn25dTgZe3JaPaOu01w9t/SVJUzDpI4j3A38E/KKt7w38sKrub+trgf3b8v7AzQDt9btaf0nSFEwsIJL8W+D2qrp8ZnOna414bebnrkyyOsnqO+64Yw4qlST1TPII4unA4UluBD7FMLT0fmCPJNu3PgcAt7TltcCBAO313YEfrP+hVXViVa2oqhVLliyZYPmStG2bWEBU1duq6oCqWgYcCZxXVa8Czgde2rodDZzVlle1ddrr51XVg44gJEnzYxrXQbwVeEuSNQznGE5q7ScBe7f2twDHTqE2SVKz/exdNl9VXQBc0JZvAJ7W6fNT4GXzUY8kaXZeSS1J6jIgJEldBoQkqcuAkCR1GRCSpC4DQpLUZUBIkroMCElSlwEhSeoyICRJXQaEJKnLgJAkdRkQkqQuA0KS1GVASJK6DAhJUpcBIUnqMiAkSV0GhCSpy4CQJHUZEJKkLgNCktRlQEiSugwISVLXqIBI8sRJFyJJWljGHkF8OMmlSX4vyR4TrUiStCCMCoiqegbwKuBAYHWSTyR57kQrkyRN1ehzEFV1PfAO4K3AbwMnJPlmkt+ZVHGSpOkZew7iSUmOB64Dng28qKoe35aPn2B9kqQp2X5kvw8AHwXeXlX3rmusqluSvGMilUmSpmpsQBwG3FtVDwAk2Q7YuaruqapTJ1adJGlqxp6D+DKwy4z1XVubJGkrNTYgdq6qH69bacu7buwNSXZuX439epJvJHlXa39kkkuSXJ/ktCQ7tvad2vqa9vqyh7ZLkqS5MDYgfpLk4HUrSX4TuHcj/QF+Bjy7qp4MHAQ8P8khwHuA46tqOXAncEzrfwxwZ1U9muHE93vG74Ykaa6NDYg3A2ckuTDJhcBpwO9v7A01WHfUsUN7FMM3nz7d2k8GXtyWj2jrtNcPTZKR9UmS5tiok9RVdVmSxwGPBQJ8s6p+Ptv7kiwCLgceDXwQ+Dbww6q6v3VZC+zflvcHbm7buz/JXcDewPfW+8yVwEqApUuXjilfkvQQbMpkfU8FngQ8BXhlkqNme0NVPVBVBwEHAE8DHt/r1p57Rwv1oIaqE6tqRVWtWLJkyejiJUmbZtQRRJJTgd8ArgQeaM0FnDLm/VX1wyQXAIcAeyTZvh1FHADc0rqtZZjKY22S7YHdgR+M3A9J0hwbex3ECuAJVfWg/9FvSJIlwM9bOOwCPIfhxPP5wEuBTwFHA2e1t6xq6xe118/blO1JkubW2IC4Bvg14NZN+Oz9gJPbeYjtgNOr6vNJrgU+leTPgCuAk1r/k4BTk6xhOHI4chO2JUmaY2MDYjFwbZJLGb6+CkBVHb6hN1TVVQznK9Zvv4HhfMT67T8FXjayHknShI0NiOMmWYQkaeEZ+zXXryT5dWB5VX05ya7AosmWJkmaprHTfb+e4eK1j7Sm/YHPTaooSdL0jb0O4o3A04G74Zc3D9pnUkVJkqZvbED8rKruW7fSrlPwK6iStBUbGxBfSfJ2YJd2L+ozgL+ZXFmSpGkbGxDHAncAVwP/ATib4f7UkqSt1NhvMf2C4ZajH51sOZKkhWLsXEzfoT9x3qPmvCJJ0oKwKXMxrbMzwxXPe819OZKkhWLUOYiq+v6Mxz9W1fsZbvwjSdpKjR1iOnjG6nYMRxS7TaQiSdKCMHaI6b0zlu8HbgRePufVSJIWjLHfYnrWpAuRJC0sY4eY3rKx16vqfXNTjiRpodiUbzE9leGubwAvAr4K3DyJoiRJ07cpNww6uKp+BJDkOOCMqnrdpAqTJE3X2Kk2lgL3zVi/D1g259VIkhaMsUcQpwKXJjmT4YrqlwCnTKwqSdLUjf0W039P8rfAv25Nr62qKyZXliRp2sYOMQHsCtxdVX8BrE3yyAnVJElaAMbecvSdwFuBt7WmHYD/M6miJEnTN/YI4iXA4cBPAKrqFpxqQ5K2amMD4r6qKtqU30keNrmSJEkLwdiAOD3JR4A9krwe+DLePEiStmpjv8X0P9u9qO8GHgv8SVWdM9HKJElTNWtAJFkEfLGqngMYCpK0jZh1iKmqHgDuSbL7PNQjSVogxl5J/VPg6iTn0L7JBFBV/3kiVUmSpm5sQHyhPSRJ24iNBkSSpVV1U1WdPF8FSZIWhtnOQXxu3UKSz2zKByc5MMn5Sa5L8o0kb2rteyU5J8n17XnP1p4kJyRZk+Sq9e6DLUmaZ7MFRGYsP2oTP/t+4A+r6vHAIcAbkzwBOBY4t6qWA+e2dYAXAMvbYyXwoU3cniRpDs0WELWB5VlV1a1V9bW2/CPgOmB/4Ahg3ZDVycCL2/IRwCk1uJjhorz9NmWbkqS5M9tJ6icnuZvhSGKXtkxbr6p6xJiNJFkGPAW4BNi3qm5l+IBbk+zTuu3Pr97CdG1ru3XMNiRJc2ujAVFVizZ3A0keDnwGeHNV3Z1kg117JXQ+byXDEBRLly7d3PIkSRuwKfeD2GRJdmAIh7+uqs+25tvWDR2159tb+1rgwBlvPwC4Zf3PrKoTq2pFVa1YsmTJ5IqXpG3cxAIiw6HCScB1VfW+GS+tAo5uy0cDZ81oP6p9m+kQ4K51Q1GSpPk39kK5h+LpwGsYrsC+srW9HXg3w+ywxwA3AS9rr50NHAasAe4BXjvB2iRJs5hYQFTV39M/rwBwaKd/AW+cVD2SpE0z0XMQkqQtlwEhSeoyICRJXQaEJKnLgJAkdRkQkqQuA0KS1GVASJK6DAhJUpcBIUnqMiAkSV0GhCSpy4CQJHUZEJKkLgNCktRlQEiSugwISVKXASFJ6jIgJEldBoQkqcuAkCR1GRCSpC4DQpLUZUBIkroMCElSlwEhSeoyICRJXQaEJKnLgJAkdRkQkqQuA0KS1GVASJK6JhYQST6W5PYk18xo2yvJOUmub897tvYkOSHJmiRXJTl4UnVJksaZ5BHEx4Hnr9d2LHBuVS0Hzm3rAC8AlrfHSuBDE6xLkjTCxAKiqr4K/GC95iOAk9vyycCLZ7SfUoOLgT2S7Dep2iRJs5vvcxD7VtWtAO15n9a+P3DzjH5rW9uDJFmZZHWS1XfcccdEi5WkbdlCOUmdTlv1OlbViVW1oqpWLFmyZMJlSdK2a74D4rZ1Q0ft+fbWvhY4cEa/A4Bb5rk2SdIM8x0Qq4Cj2/LRwFkz2o9q32Y6BLhr3VCUJGk6tp/UByf5JPBMYHGStcA7gXcDpyc5BrgJeFnrfjZwGLAGuAd47aTqkiSNM7GAqKpXbuClQzt9C3jjpGqRJG26hXKSWpK0wBgQkqQuA0KS1GVASJK6DAhJUpcBIUnqMiAkSV0GhCSpy4CQJHUZEJKkLgNCktRlQEiSugwISVKXASFJ6jIgJEldBoQkqcuAkCR1GRCSpC4DQpLUZUBIkroMCElSlwEhSeoyICRJXQaEJKnLgJAkdRkQkqQuA0KS1GVASJK6DAhJUpcBIUnqMiAkSV0LKiCSPD/Jt5KsSXLstOuRpG3Z9tMuYJ0ki4APAs8F1gKXJVlVVddOtzJJC92yY78w7RK2SgvpCOJpwJqquqGq7gM+BRwx5ZokaZu1kAJif+DmGetrW5skaQoWzBATkE5bPahTshJY2VZ/nORbD3F7i4HvPcT3bpa8ZxpbBaa4z1PkPm8btrl9zns2a59/fUynhRQQa4EDZ6wfANyyfqeqOhE4cXM3lmR1Va3Y3M/ZkrjP2wb3edswH/u8kIaYLgOWJ3lkkh2BI4FVU65JkrZZC+YIoqruT/L7wBeBRcDHquobUy5LkrZZCyYgAKrqbODsedrcZg9TbYHc522D+7xtmPg+p+pB54ElSVpQ5yAkSQvIVh8Qs03fkWSnJKe11y9Jsmz+q5xbI/b5LUmuTXJVknOTjPrK20I2dpqWJC9NUkm2+G+8jNnnJC9vf9bfSPKJ+a5xro34u700yflJrmh/vw+bRp1zJcnHktye5JoNvJ4kJ7Sfx1VJDp7TAqpqq30wnOz+NvAoYEfg68AT1uvze8CH2/KRwGnTrnse9vlZwK5t+Q3bwj63frsBXwUuBlZMu+55+HNeDlwB7NnW95l23fOwzycCb2jLTwBunHbdm7nP/wY4GLhmA68fBvwtw3VkhwCXzOX2t/YjiDHTdxwBnNyWPw0cmqR30d6WYtZ9rqrzq+qetnoxwzUnW7Kx07T8KfA/gJ/OZ3ETMmafXw98sKruBKiq2+e5xrk2Zp8LeERb3p3OtVRbkqr6KvCDjXQ5AjilBhcDeyTZb662v7UHxJjpO37Zp6ruB+4C9p6X6iZjU6csOYbhfyBbsln3OclTgAOr6vPzWdgEjflzfgzwmCT/kOTiJM+ft+omY8w+Hwe8Oslahm9E/qf5KW1qJjpF0YL6musEjJm+Y9QUH1uQ0fuT5NXACuC3J1rR5G10n5NsBxwP/O58FTQPxvw5b88wzPRMhqPEC5M8sap+OOHaJmXMPr8S+HhVvTfJbwGntn3+xeTLm4qJ/v7a2o8gxkzf8cs+SbZnOCzd2CHdQjdqypIkzwH+GDi8qn42T7VNymz7vBvwROCCJDcyjNWu2sJPVI/9u31WVf28qr4DfIshMLZUY/b5GOB0gKq6CNiZYZ6mrdWof+8P1dYeEGOm71gFHN2WXwqcV+3szxZq1n1uwy0fYQiHLX1cGmbZ56q6q6oWV9WyqlrGcN7l8KpaPZ1y58SYv9ufY/hCAkkWMww53TCvVc6tMft8E3AoQJLHMwTEHfNa5fxaBRzVvs10CHBXVd06Vx++VQ8x1Qam70jy34DVVbUKOInhMHQNw5HDkdOrePON3Oc/Bx4OnNHOx99UVYdPrejNNHKftyoj9/mLwPOSXAs8APzXqvr+9KrePCP3+Q+Bjyb5A4ahlt/dkv/Dl+STDEOEi9t5lXcCOwBU1YcZzrMcBqwB7gFeO6fb34J/dpKkCdrah5gkSQ+RASFJ6jIgJEldBoQkqcuAkCR1GRCaiiQPJLkyyTVJzkiya2vfJclXkixKsmxDs1jO+JxnJtmk6TOSXLDuIrn2/fHzkjyirf/fh7pPmyvJl5PsOQefc1yS/zIXNXU+e8ckX20XlWorZ0BoWu6tqoOq6onAfcB/bO3/HvhsVT0wT3UcBny9qu4GqKp/NU/b7TmVYXbhBatNkncu8Ipp16LJMyC0EFwIPLotvwo4a/0O7WjiwiRfa4+Zv8gfkeTMdt+DD7e5l0jyvCQXtf5nJHl4Z9u/sr0kP27Pz2xHMqcn+X9J3p3kVUkuTXJ1kt9o/V6U4T4iV7QjgH1b+5Ik57RtfyTJd9vVzCR5dfucK9tri9rmVzHMJTQXntyOjK5P8vq23ST583bUdnWSV7T2U5P8clbUJH+d5PAk/3JGnVclWTdNx+faz01bu2nPd+5j23wAP27P2zP8gn4Dwxz//zSjzzLaPPjArsDObXk5w5WzMFxl+lOGewQsAs5hmDJlMcO9Hx7W+r0V+JO2fAHtfhDAd4HdOnU9E/ghsB+wE/CPwLvaa28C3t+W9+SfLzh9HfDetvwB4G1t+fkMV/UuBh4P/A2wQ3vtr4CjZmz/emDvzs/rNODKzuOoTt/jGO6VsEvb5s3AvwD+Xfv5LAL2ZZiWYj+GyRo/1967O/Cd9ufyl8CrWvuOwC5teRFwx7T/DvmY/MNxRE3LLkmubMsXMkx5spjhl3LPDsAHkhzEMG3EY2a8dmlV3QC/nJrgGQyh8QTgH9p0IjsCF3U+d6+q+tEGtnlZtXltknwb+FJrv5o2xxHD5GinZZiDf0eGX660Gl4CUFV/l+TO1n4o8JvAZa2uXYCZ82HdzvDL/FemxKiqTR3SOauq7gXuTXI+w70UngF8sobhu9uSfAV4alWtSvLBJPsAvwN8poZpLS4C/jjJAQzDfte3Wh5Icl+S3Tbys9NWwIDQtNxbVQfNbEhyL8Pkaj1/ANwGPJlhaHTmTX/Wny+mGKZBPqeqZhuyuT/JdtWfDnrmLLe/mLH+C/75385fAu9rv2SfyfC/d+hPw7yu/eSqetsGXt8ZuPdBb0pOAx7b6f++qjql076hn8mGnMowbHQkw3kgquoTSS4BXgh8Mcnrquq81n8nto4bL2kjPAehBaOGO58tStILid2BW9sv8tcwDHOs87QMM3xux3Dy9O8ZZmx9epJHAyTZNclj1v9QhimwH7UZZe/OMPwE/zwrMK2Gl7dtP49hKAqGE7wvbf9bJ8leafcEz3BI8WvAjetvpKpeUcNJ/fUfvXAAOCLJzkn2Zhguu4xhyO0V7RtiSxhuZ3lp6/9x4M1tW99o9TwKuKGqTmA4P/Kk1r43wxDTz0f+jLSFMiC00HyJYShkfX8FHJ3kYobhpZ/MeO0i4N3ANQxDPGdW1R0MNwj6ZJKrGALjcZ3P/QLDL9CH6jiGWXEvBL43o/1dDDOpfg14AXAr8KOquhZ4B/ClVtc5DOcBYBh6uriGOxturksZ9u1i4E+r6hbgTOAqhvMT5wF/VFX/BFBVtwHXAf97xme8ArimDQU+DlgXRs9imEVUWzlnc9WCkuFeFW+pqtfM0/b2Y7in73Pn+HN3Ah5oY/m/BXxo/SG1znv+AlhVVefOZS1jZLgO5Wrg4Kq6a5a+n2U4Af+teSlOU+M5CC0oVXVFkvOTLKp5uBaiqm5N8tEkj6h2LcQcWQqc3oa97gNeP+I910wpHJ4DfIzhfMZs4bAjwzeeDIdtgEcQkqQuz0FIkroMCElSlwEhSeoyICRJXQaEJKnLgJAkdf1/kkg6TGcx2o8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_prob = mod.predict_proba(x_test)\n",
    "\n",
    "plt.hist(y_pred_prob[:, 0])\n",
    "plt.xlabel('P(label(image) = boys)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on all pixels with CART, only 0.99 of images with very low/high scores: 0.666\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob_1d = y_pred_prob[:, 0]\n",
    "y_pred_low_high_id = np.argwhere(( y_pred_prob_1d <= 0.001) | (y_pred_prob_1d >= 0.999)).reshape(-1)\n",
    "y_pred_low_high = y_pred_prob[y_pred_low_high_id, 0]\n",
    "y_pred_low_high_temp = y_pred_low_high.copy()\n",
    "y_pred_low_high[y_pred_low_high_temp < 0.5] = 1\n",
    "y_pred_low_high[y_pred_low_high_temp > 0.5] = 0\n",
    "y_test_low_high = y_test[y_pred_low_high_id]\n",
    "\n",
    "conf = confusion_matrix(y_test_low_high, y_pred_low_high)\n",
    "acc = (conf[0, 0] + conf[1, 1]) / len(y_test_low_high)\n",
    "print('Test accuracy on all pixels with CART, only %.2f of images with very low/high scores: %.3f' % (len(y_test_low_high)/len(y_test), acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
